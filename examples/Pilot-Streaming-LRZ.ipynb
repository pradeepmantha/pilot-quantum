{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LRZ Linux Cluster: Getting Started with Pilot-Streaming \n",
    "\n",
    "In the first step we need to import all required packages and modules into the Python Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-28T17:59:21.386383Z",
     "start_time": "2017-12-28T17:59:21.364643Z"
    }
   },
   "outputs": [],
   "source": [
    "# System Libraries\n",
    "import sys, os\n",
    "sys.path.append(\"..\")\n",
    "import pandas as pd\n",
    "\n",
    "## logging\n",
    "import logging\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "logging.getLogger().setLevel(logging.ERROR)\n",
    "logging.getLogger(\"py4j\").setLevel(logging.ERROR)\n",
    " \n",
    "\n",
    "# Pilot-Streaming\n",
    "import pilot.streaming\n",
    "sys.modules['pilot.streaming']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Pilot-Compute Description is a simple key/value style description of the cluster environment that should be started. Alternatively, the commandline tool delivered with this package can be used:\n",
    "\n",
    "     pilot-streaming --resource=slurm://localhost --queue=normal --walltime=59 --number_cores=48 --framework spark "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-28T18:00:04.950564Z",
     "start_time": "2017-12-28T17:59:22.095228Z"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "### Required Spark configuration that needs to be provided before pyspark is imported and JVM started\n",
    "#os.environ[\"SPARK_LOCAL_IP\"]='129.114.58.2' #must be done before pyspark is loaded\n",
    "import pyspark\n",
    "\n",
    "pilot_compute_description = {\n",
    "    \"resource\":\"slurm+ssh://mpp2-login6\",\n",
    "    \"working_directory\": os.path.join('/home/hpc/ug201/di57hah/project/', \"work\"),\n",
    "    \"number_cores\": 56,\n",
    "    \"walltime\": 59,\n",
    "    \"type\":\"spark\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start Spark Cluster and Wait for Startup Completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "spark_pilot = pilot.streaming.PilotComputeService.create_pilot(pilot_compute_description)\n",
    "spark_pilot.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_pilot.get_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sc = pyspark.SparkContext(master=\"spark://129.114.58.135:7077\", appName=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-28T17:51:55.430862Z",
     "start_time": "2017-12-28T17:51:55.093479Z"
    }
   },
   "outputs": [],
   "source": [
    "sc = spark_pilot.get_context()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = sc.parallelize([1,2,3])\n",
    "rdd.map(lambda a: a*a).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_pilot.cancel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Kafka\n",
    "\n",
    "## HPC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pilot_compute_description = {\n",
    "    \"resource\":\"slurm://localhost\",\n",
    "    \"working_directory\": os.path.join('/work/01131/tg804093/wrangler/', \"work\"),\n",
    "    \"number_cores\": 48,\n",
    "    \"project\": \"TG-MCB090174\",\n",
    "    \"queue\": \"normal\",\n",
    "    \"walltime\": 59,\n",
    "    \"type\":\"kafka\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "kafka_pilot = pilot.streaming.PilotComputeService.create_pilot(pilot_compute_description)\n",
    "kafka_pilot.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kafka_pilot.get_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kafka_pilot.cancel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jetstream Cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.system(\"type python\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# System Libraries\n",
    "import sys, os\n",
    "import pandas as pd\n",
    "\n",
    "## logging\n",
    "import logging\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "logging.getLogger().setLevel(logging.ERROR)\n",
    "logging.getLogger(\"py4j\").setLevel(logging.ERROR)\n",
    " \n",
    "\n",
    "# Pilot-Streaming\n",
    "import pilot.streaming\n",
    "sys.modules['pilot.streaming']\n",
    "\n",
    "RESOURCE_URL_DASK = \"ssh://aluckow@js-129-114-17-61.jetstream-cloud.org\"\n",
    "RESOURCE_URL_KAFKA = \"ssh://aluckow@js-129-114-17-61.jetstream-cloud.org\"\n",
    "WORKING_DIRECTORY = os.path.join(os.environ[\"HOME\"], \"work\")\n",
    "\n",
    "pilot_compute_description = {\n",
    "    \"resource\": RESOURCE_URL_KAFKA,\n",
    "    \"working_directory\": WORKING_DIRECTORY,\n",
    "    \"number_of_nodes\": 1,\n",
    "    \"cores_per_node\": 1,\n",
    "    \"config_name\": \"jetstream\",\n",
    "    \"walltime\": 59,\n",
    "    \"type\": \"kafka\"\n",
    "}\n",
    "kafka_pilot = pilot.streaming.PilotComputeService.create_pilot(pilot_compute_description)\n",
    "kafka_pilot.wait()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import distributed\n",
    "\n",
    "pilot_compute_description = {\n",
    "    \"resource\":\"slurm://localhost\",\n",
    "    \"working_directory\": os.path.join('/work/01131/tg804093/wrangler/', \"work\"),\n",
    "    \"number_cores\": 48,\n",
    "    \"project\": \"TG-MCB090174\",\n",
    "    \"queue\": \"normal\",\n",
    "    \"walltime\": 59,\n",
    "    \"type\":\"dask\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "dask_pilot = pilot.streaming.PilotComputeService.create_pilot(pilot_compute_description)\n",
    "dask_pilot.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dask_pilot.get_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import distributed\n",
    "dask_client  = distributed.Client(dask_pilot.get_details()['master_url'])\n",
    "dask_client.scheduler_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dask_client.gather(dask_client.map(lambda a: a*a, range(10)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "toc_cell": false,
   "toc_number_sections": true,
   "toc_threshold": 6,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
